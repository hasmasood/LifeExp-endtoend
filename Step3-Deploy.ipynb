{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initializing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     active environment : aws_env\n",
      "    active env location : /home/hassan101/anaconda3/envs/aws_env\n"
     ]
    }
   ],
   "source": [
    "#Active environment should be aws_env\n",
    "!conda info | grep 'active env'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get AWS credentials from environment\n",
    "import os\n",
    "aws_akid = os.environ['AWS_KID']\n",
    "aws_sak = os.environ['AWS_AK']\n",
    "\n",
    "#Importing libraries\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import io\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting processed data from S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Key': 'lifexp-processed.csv', 'LastModified': datetime.datetime(2023, 2, 9, 9, 16, 24, tzinfo=tzutc()), 'ETag': '\"9e138a0af6f65a9b4338da770613527c\"', 'Size': 98812, 'StorageClass': 'STANDARD'}\n",
      "Successful S3 get_object response. Status - 200\n",
      "(2556, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Adult mortality</th>\n",
       "      <th>Under-five deaths</th>\n",
       "      <th>Thinness 5-9 years</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Status_Developed</th>\n",
       "      <th>Status_Developing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.479</td>\n",
       "      <td>263</td>\n",
       "      <td>83</td>\n",
       "      <td>17.3</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.476</td>\n",
       "      <td>271</td>\n",
       "      <td>86</td>\n",
       "      <td>17.5</td>\n",
       "      <td>58</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.470</td>\n",
       "      <td>268</td>\n",
       "      <td>89</td>\n",
       "      <td>17.7</td>\n",
       "      <td>62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.463</td>\n",
       "      <td>272</td>\n",
       "      <td>93</td>\n",
       "      <td>18.0</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.454</td>\n",
       "      <td>275</td>\n",
       "      <td>97</td>\n",
       "      <td>18.2</td>\n",
       "      <td>68</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   HIV/AIDS  Income composition of resources  Adult mortality  \\\n",
       "0       0.1                            0.479              263   \n",
       "1       0.1                            0.476              271   \n",
       "2       0.1                            0.470              268   \n",
       "3       0.1                            0.463              272   \n",
       "4       0.1                            0.454              275   \n",
       "\n",
       "   Under-five deaths  Thinness 5-9 years  Polio  Status_Developed  \\\n",
       "0                 83                17.3      6                 0   \n",
       "1                 86                17.5     58                 0   \n",
       "2                 89                17.7     62                 0   \n",
       "3                 93                18.0     67                 0   \n",
       "4                 97                18.2     68                 0   \n",
       "\n",
       "   Status_Developing  \n",
       "0                  1  \n",
       "1                  1  \n",
       "2                  1  \n",
       "3                  1  \n",
       "4                  1  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Authentication\n",
    "res_s3 = boto3.resource('s3', aws_access_key_id=aws_akid, aws_secret_access_key= aws_sak)\n",
    "client_s3 = boto3.client('s3', aws_access_key_id=aws_akid, aws_secret_access_key= aws_sak)\n",
    "\n",
    "# List all objects in bucket\n",
    "bucket_name = 'reg-dataset-processed'\n",
    "\n",
    "response = client_s3.list_objects_v2(Bucket=bucket_name)\n",
    "for obj in response['Contents']:\n",
    "    print(obj)\n",
    "\n",
    "response = client_s3.get_object(Bucket=bucket_name, Key=\"lifexp-processed.csv\")\n",
    "\n",
    "status = response.get(\"ResponseMetadata\", {}).get(\"HTTPStatusCode\")\n",
    "\n",
    "if status == 200:\n",
    "    print(f\"Successful S3 get_object response. Status - {status}\")\n",
    "    df = pd.read_csv(response.get(\"Body\"))\n",
    "else:\n",
    "    print(f\"Unsuccessful S3 get_object response. Status - {status}\")\n",
    "\n",
    "#Seperate feature and labels\n",
    "X=df.iloc[:,:-1]\n",
    "y=df.iloc[:,[-1]]\n",
    "\n",
    "#Perform OHE\n",
    "X_ohe = pd.get_dummies(X)\n",
    "print(X_ohe.shape)\n",
    "X_ohe.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEPLOYMENT AND MAKING PREDICTIONS (single sample only)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepping sample"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking random sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual label for data: 9.39\n",
      "These are the features with data shape:(1, 8)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>HIV/AIDS</th>\n",
       "      <th>Income composition of resources</th>\n",
       "      <th>Adult mortality</th>\n",
       "      <th>Under-five deaths</th>\n",
       "      <th>Thinness 5-9 years</th>\n",
       "      <th>Polio</th>\n",
       "      <th>Status_Developed</th>\n",
       "      <th>Status_Developing</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.1</td>\n",
       "      <td>0.719</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>3.3</td>\n",
       "      <td>99</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     HIV/AIDS  Income composition of resources  Adult mortality  \\\n",
       "611       0.1                            0.719               19   \n",
       "\n",
       "     Under-five deaths  Thinness 5-9 years  Polio  Status_Developed  \\\n",
       "611                  1                 3.3     99                 0   \n",
       "\n",
       "     Status_Developing  \n",
       "611                  1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "random_number = random.randint(0, len(df))\n",
    "\n",
    "sample = X_ohe.iloc[[random_number]]\n",
    "sample_label = y.iloc[random_number]['Total expenditure']\n",
    "\n",
    "print('Actual label for data:', sample_label)\n",
    "print(f'These are the features with data shape:{sample.shape}')\n",
    "\n",
    "sample.to_csv('sample.csv', index=True)\n",
    "sample.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepping sample as dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'HIV/AIDS': [0.1],\n",
       " 'Income composition of resources': [0.719],\n",
       " 'Adult mortality': [19],\n",
       " 'Under-five deaths': [1],\n",
       " 'Thinness 5-9 years': [3.3],\n",
       " 'Polio': [99],\n",
       " 'Status_Developed': [0],\n",
       " 'Status_Developing': [1]}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predicting with script (passing without additional header)\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model = pickle.load( open('model_fromscratch.pkl', 'rb') )\n",
    "scaler = pickle.load( open('scaling.pkl', 'rb') )\n",
    "\n",
    "#Importing sample data and preparing data in form of JSON\n",
    "sample = pd.read_csv('sample.csv', index_col=0)\n",
    "sample_dic = sample.to_dict('list') #This will only use column-values pair for dic, index will be ignored. To use index as header for JSON later, use 'index' as argument\n",
    "sample_dic"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick check on predictions locally (we will convert to JSON anyway for local testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1, 8)\n",
      "Predicted value: 7.342199999999992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan101/anaconda3/envs/aws_env/lib/python3.8/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Converting dictionary to JSON\n",
    "data_as_json=json.dumps(sample_dic)\n",
    "data_as_json\n",
    "\n",
    "#Loading JSON back to dictionary\n",
    "data_as_dic = json.loads(data_as_json)\n",
    "\n",
    "#Making predictions from data dictionary\n",
    "data_as_array = np.array(list(data_as_dic.values())).reshape(1,-1)\n",
    "print('Data shape:', data_as_array.shape)\n",
    "data_sc=scaler.transform(data_as_array)\n",
    "output=model.predict(data_sc)\n",
    "print('Predicted value:', output[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions from Flask"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that Flask is not recommended to run in prod environment. It won't handle multiple requests. Gunicorn/docker/cloud are better alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For flask, converting to JSON isn't needed. Requests are sent as dictionary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a script to execute in deployment environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting app_api.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_api.py\n",
    "\n",
    "from flask import Flask, request,jsonify\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "app = Flask('lifeexp')\n",
    "model = pickle.load( open('model_fromscratch.pkl', 'rb') )\n",
    "scaler = pickle.load( open('scaling.pkl', 'rb') )\n",
    "\n",
    "@app.route('/predict_api', methods=['POST'])\n",
    "def predict_api():\n",
    "    data_as_dic=request.get_json()\n",
    "    data_as_array = np.array(list(data_as_dic.values())).reshape(1,-1)\n",
    "    print('Data shape:', data_as_array.shape)\n",
    "    print('Data shape:', data_as_array.shape)\n",
    "    data_sc=scaler.transform(data_as_array)\n",
    "    output=model.predict(data_sc)\n",
    "    print('Predicted value:', output[0])\n",
    "    return jsonify(output[0])\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Execute the above file in deployment environment as follows:\n",
    "\n",
    "`\n",
    "python app_api.py\n",
    "`\n",
    "\n",
    "\n",
    "Then make predictions like below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 7.958399999999994\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url= 'http://localhost:9696/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Local predictions with manual inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1, 8)\n",
      "Predicted value: 2.5392000000000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan101/anaconda3/envs/aws_env/lib/python3.8/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Without additional header\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model = pickle.load( open('model_fromscratch.pkl', 'rb') )\n",
    "scaler = pickle.load( open('scaling.pkl', 'rb') )\n",
    "\n",
    "#Preparing data in form of JSON\n",
    "dic = {\n",
    "\t\t\"HIV/AIDS\": 0.1,\n",
    "\t\t\"Income composition of resources\": 0.624,\n",
    "\t\t\"Adult mortality\": 213.0,\n",
    "\t\t\"Under-five deaths\": 237.0,\n",
    "\t\t\"Thinness 5-9 years\": 1.9,\n",
    "\t\t\"Polio\": 79.0,\n",
    "\t\t\"Status_Developed\": 0.0,\n",
    "\t\t\"Status_Developing\": 1.0\n",
    "\t}\n",
    "data_as_json=json.dumps(dic)\n",
    "data_as_json\n",
    "\n",
    "#Loading JSON data on the app, and transforming for predictions\n",
    "data_as_dic = json.loads(data_as_json)\n",
    "data_as_array = np.array(list(data_as_dic.values())).reshape(1,-1)\n",
    "print('Data shape:', data_as_array.shape)\n",
    "data_sc=scaler.transform(data_as_array)\n",
    "output=model.predict(data_sc)\n",
    "print('Predicted value:', output[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1, 8)\n",
      "Predicted value: 2.5392000000000023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hassan101/anaconda3/envs/aws_env/lib/python3.8/site-packages/sklearn/base.py:409: UserWarning: X does not have valid feature names, but StandardScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#With additional \"data\"\" header (STILL BUGGY !!!!!)\n",
    "import pickle\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "model = pickle.load( open('model_fromscratch.pkl', 'rb') )\n",
    "scaler = pickle.load( open('scaling.pkl', 'rb') )\n",
    "\n",
    "#Preparing data in form of JSON\n",
    "dic = {\n",
    "    \"data\":{\n",
    "\t\t\"HIV/AIDS\": 0.1,\n",
    "\t\t\"Income composition of resources\": 0.624,\n",
    "\t\t\"Adult mortality\": 213.0,\n",
    "\t\t\"Under-five deaths\": 237.0,\n",
    "\t\t\"Thinness 5-9 years\": 1.9,\n",
    "\t\t\"Polio\": 79.0,\n",
    "\t\t\"Status_Developed\": 0.0,\n",
    "\t\t\"Status_Developing\": 1.0\n",
    "\t}\n",
    "}\n",
    "data_as_json=json.dumps(dic['data'])\n",
    "data_as_json\n",
    "\n",
    "#Loading JSON data on the app, and transforming for predictions\n",
    "data_as_dic = json.loads(data_as_json)\n",
    "data_as_array = np.array(list(data_as_dic.values())).reshape(1,-1)\n",
    "print('Data shape:', data_as_array.shape)\n",
    "data_sc=scaler.transform(data_as_array)\n",
    "output=model.predict(data_sc)\n",
    "print('Predicted value:', output[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on Postman"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data to put in Postman API body as raw data\n",
    "{\n",
    "    \"HIV/AIDS\": 0.1,\n",
    "    \"Income composition of resources\": 0.624,\n",
    "    \"Adult mortality\": 213.0,\n",
    "    \"Under-five deaths\": 237.0,\n",
    "    \"Thinness 5-9 years\": 1.9,\n",
    "    \"Polio\": 79.0,\n",
    "    \"Status_Developed\": 0.0,\n",
    "    \"Status_Developing\": 1.0\n",
    "}\n",
    "\n",
    "#Use this URL\n",
    "http://localhost:9696/predict_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2.5848000000000018\n"
     ]
    }
   ],
   "source": [
    "# Alternatively, this will work too:\n",
    "\n",
    "sample_dic = {\n",
    "    \"HIV/AIDS\": 0.1,\n",
    "    \"Income composition of resources\": 0.624,\n",
    "    \"Adult mortality\": 213.0,\n",
    "    \"Under-five deaths\": 237.0,\n",
    "    \"Thinness 5-9 years\": 1.9,\n",
    "    \"Polio\": 79.0,\n",
    "    \"Status_Developed\": 0.0,\n",
    "    \"Status_Developing\": 1.0\n",
    "}\n",
    "\n",
    "import requests\n",
    "url= 'http://localhost:9696/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on web"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing app_web.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile app_web.py\n",
    "\n",
    "from flask import Flask, request, app, jsonify, url_for, render_template\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "app = Flask(__name__)\n",
    "model = pickle.load( open('model_fromscratch.pkl', 'rb') )\n",
    "scaler = pickle.load( open('scaling.pkl', 'rb') )\n",
    "\n",
    "@app.route('/')\n",
    "def home():\n",
    "    return render_template('home.html')\n",
    "\n",
    "@app.route('/predict_web', methods=['POST'])\n",
    "def predict():\n",
    "    data_as_float = [float(x) for x in request.form.values()]\n",
    "    data_as_array = np.array(data_as_float).reshape(1,-1)\n",
    "    print('Data shape:', data_as_array.shape)\n",
    "    data_sc=scaler.transform(data_as_array)\n",
    "    output=model.predict(data_sc)\n",
    "    print('Predicted value:', output[0])\n",
    "    return render_template('home.html', prediction_text= \"The life expentency is {}\".format(output[0]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run(debug=True, host='0.0.0.0', port=9696)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on gunicorn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run this code in the deployment environment to start the service:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "gunicorn --bind=0.0.0.0:9696 app_api:app\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next you can send POST request as usual to get the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 7.958399999999994\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url= 'http://localhost:9696/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on docker"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Make an image with dockerfile instructions, then run this command in terminal (not in docker terminal)\n",
    "```\n",
    "docker run -it --rm -p 9696:9696 lifeexp\n",
    "```\n",
    "You need to make sure not to run this in docker terminal with VSC, since the port will be used up by VSC. Don't forget to map docker port with local by 9696:9696 mapping. The --rm removed all temporary files after container is closed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 2.5848000000000018\n"
     ]
    }
   ],
   "source": [
    "#Once container is started, use the POST request to get predictions\n",
    "import requests\n",
    "url= 'http://localhost:9696/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions on AWS Elastic beanstalk"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, you need to install the elastic beanstalk library in working environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install awsebcli"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if installation is working fine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EB CLI 3.20.3 (Python 3.8.0)\n"
     ]
    }
   ],
   "source": [
    "!eb --version"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize docker-based project:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "!eb init -p docker life-exp-service --profile usr_hassan"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This profile usr_hassan contains AWS credentials stored in  ~/.aws/config file under [profile usr_hassan]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check config.yml file for easticbeanstalk and make sure default_region is set to ap-southeast-2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "branch-defaults:\n",
      "  main:\n",
      "    environment: null\n",
      "    group_suffix: null\n",
      "global:\n",
      "  application_name: life-exp-service\n",
      "  branch: null\n",
      "  default_ec2_keyname: null\n",
      "  default_platform: Docker\n",
      "  default_region: ap-southeast-2\n",
      "  include_git_submodules: true\n",
      "  instance_profile: null\n",
      "  platform_name: null\n",
      "  platform_version: null\n",
      "  profile: usr_hassan\n",
      "  repository: null\n",
      "  sc: git\n",
      "  workspace_type: Application\n"
     ]
    }
   ],
   "source": [
    "!cat .elasticbeanstalk/config.yml"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test by executing locally (make sure Docker is operational)\n",
    "\n",
    "`\n",
    "eb local run --port 9696\n",
    "`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if predictions are working locally:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 7.958399999999994\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url= 'http://localhost:9696/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create the service on cloud (this is not free):\n",
    "\n",
    "`\n",
    "eb create life-exp-service\n",
    "`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once finished, copy URL from this line:\n",
    "\n",
    "\n",
    "2023-02-14 00:47:19    INFO    Application available at life-exp-service.eba-snms8sq2.ap-southeast-2.elasticbeanstalk.com."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify URL section between {http://} and {/predict_api} for POST request and make predictions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted label: 7.958399999999994\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "url= 'http://life-exp-service.eba-snms8sq2.ap-southeast-2.elasticbeanstalk.com/predict_api'\n",
    "output=requests.post(url, json=sample_dic)\n",
    "print('Predicted label:', output.json())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terminate the service from cloud afterwards to avoid paying a hefty bill"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "aws_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c52f623ceac37ddf7faf652ecec1076e97b4693849be5fb4832d0833d01e4686"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
